{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-layer NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be making 2-layer NN: input and output layer, no hidden layer. Simple thing to startu but good to gain general understanding.\n",
    "\n",
    "First let's mark our input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's mark our output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[0,0,1,1]]).T\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to correctly guess values in output layer based on input layer values. To do that we need to transfer input layer values through synapses to output layer. this where transformation takes place by using activation function which uses weights from synapses. First let's set those weights randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16595599],\n",
       "       [ 0.44064899],\n",
       "       [-0.99977125]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed\n",
    "np.random.seed(1)\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2*np.random.random((3,1)) - 1\n",
    "syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start passing input values to output layer. We will be using sigmoid activation function because of it's simplicity (there are more of activation functions). Activation function is just a function which takes all the input to the node and transforms it into output (it could be very simple, for example: if input sum > 2: return 1, else: 0). \n",
    "\n",
    "As mentioned we'll be using sigmoid function, which has following form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "sigmoid = \\frac {1}{1+e ^{-net_i}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In python it has following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate net (net refers to net input to layer), we could use following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "net_i =  \\sum {weight_i}*{input_i}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula refers that we should multiply input with weight of synapses and do so with all the synapses that reach to specific node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In python we could calculate net input to output layer as following (just dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99977125],\n",
       "       [-0.55912226],\n",
       "       [-1.16572724],\n",
       "       [-0.72507825]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,syn0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so we could pass it through sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2689864 ],\n",
       "       [0.36375058],\n",
       "       [0.23762817],\n",
       "       [0.3262757 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.dot(X,syn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More about sigmoid function. We could see how output changes when we change values of input in the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x16f8fb70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/tuzNr6crZegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x34b7ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sigmoid=pd.DataFrame.from_dict({'x':[x for x in range(-10,10)]})\n",
    "df_sigmoid=df_sigmoid.set_index(df_sigmoid.x)\n",
    "df_sigmoid['sig']=sigmoid(df_sigmoid.x)\n",
    "plt_sig=df_sigmoid.sig.plot(title='Sigmoid function input vs output')\n",
    "plt_sig.set_xlabel('input')\n",
    "plt_sig.set_ylabel('output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot sigmoid function output is between 0 and 1 (nicely normalizes data). Also we see from the plot that output has most steepest growth between -2.5 and 2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we have very  simple NN we have reached NN output. To assess how good our model is we have to calculate error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "error_i = target_i-output_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2689864 ],\n",
       "       [-0.36375058],\n",
       "       [ 0.76237183],\n",
       "       [ 0.6737243 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=sigmoid(np.dot(X,syn0))\n",
    "error=y-output\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total error can be calulated by this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "error= \\sum \\frac 12 (target_i-output_i)^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to reduce error. To do that we need to change the weights. But how much? We could do it as a guess (change weights in some way an observe if error is reducing). But of course it is not very efficient (especially with large NNs). This is a part where (partial) derivative comes in hand. If we take derivative of output layer, we'll get to know the slope of each point. \n",
    "\n",
    "What we need is to calculate following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac {\\partial error}{\\partial w_i}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It states we need to find each weights share in total error. Previous formula could be calculated like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac {\\partial error}{\\partial w_i} = \\frac {\\partial error} {\\partial output_i} * \\frac {\\partial output_i} {\\partial net_i} * \\frac {\\partial net_i} {\\partial w_i}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find each component. First partial derivative of error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac {\\partial error} {\\partial output_i} = target_i -output_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then second component:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac {\\partial out_i} {\\partial net_i} = output_i * (1-output_i)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is derivative of sigmoid function which is not covered in this page, google it and find out how it is found.\n",
    "\n",
    "And now third component:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac {\\partial net_i} {\\partial w_i} = input_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plug it all back in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac {\\partial error}{\\partial w_i} =  (target_i-output_i) * output_i*(1-output_i) * input_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'll calculate:\n",
    " - size of the error (target if i - output of i)\n",
    " - input (input of i)\n",
    " - derivative sigmoid function. If slope is steep (see plot about sigmoid derivative), we want to adjust weights more because we are not very sure, but if we are more confident (for larger numbers sigmoid function has shallow gradient). Derivative achieves that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In python this look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-82dbdb76defb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiply how much we missed by the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# slope of the sigmoid at the values in l1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0moutput_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_error\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msigmoid_der\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'l1' is not defined"
     ]
    }
   ],
   "source": [
    "#derivative of sigmoid function\n",
    "def sigmoid_der(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "output_error = y - output\n",
    "\n",
    "# multiply how much we missed by the \n",
    "# slope of the sigmoid at the values in l1\n",
    "output_delta = output_error * sigmoid_der(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-82995b7b4095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msyn0\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_delta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'l0' is not defined"
     ]
    }
   ],
   "source": [
    "syn0 += np.dot(l0.T,output_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real life above steps are repeated many-many times to reduce error (NN learns a bit in ever iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to use as a class to implement 2-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        # Seed to repeat results\n",
    "        np.random.seed(1)\n",
    "        #assign synaptic weights randomly with mean of 0\n",
    "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in range(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network (a single neuron).\n",
    "            output = self.think(training_set_inputs)\n",
    "\n",
    "            # Calculate the error (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            error = training_set_outputs - output\n",
    "            \n",
    "            #print error\n",
    "            if (iteration% 10000) == 0:\n",
    "                print(\"Error:\" + str(np.mean(np.abs(error))))\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of the Sigmoid curve.\n",
    "            # This means less confident weights are adjusted more.\n",
    "            # This means inputs, which are zero, do not cause changes to the weights.\n",
    "            adjustment = np.dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.synaptic_weights += adjustment\n",
    "\n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs):\n",
    "        # Pass inputs through our neural network (our single neuron).\n",
    "        return self.__sigmoid(np.dot(inputs, self.synaptic_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.5172082754380926\n",
      "Error:0.007954845066726928\n",
      "Error:0.005597823963397232\n",
      "Error:0.004560869180125656\n",
      "Error:0.0039448224333886225\n",
      "Error:0.0035253088374209004\n"
     ]
    }
   ],
   "source": [
    "#Intialise a single neuron neural network.\n",
    "neural_network = NeuralNetwork()\n",
    "\n",
    "# The training set. We have 4 examples, each consisting of 3 input values\n",
    "# and 1 output value.\n",
    "training_set_inputs = np.array([  [0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1] ])\n",
    "training_set_outputs =  np.array([[0,0,1,1]]).T\n",
    "\n",
    "# Train the neural network using a training set.\n",
    "# Do it 60,000 times and make small adjustments each time.\n",
    "neural_network.train(training_set_inputs, training_set_outputs, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00390231],\n",
       "       [0.00318165],\n",
       "       [0.99740399],\n",
       "       [0.99681556]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.think(training_set_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=np.array([[0,0,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syn0=2*np.random.random((3,1))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39533485],\n",
       "       [-0.70648822],\n",
       "       [-0.81532281]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33777615],\n",
       "       [0.21271463],\n",
       "       [0.3026181 ],\n",
       "       [0.18689996]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pass\n",
    "l0=X\n",
    "l1=sigmoid(np.dot(l0, syn0))\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error=y-l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_delta=error*(sigmoid_der(l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syn0+=np.dot(l0.T, l1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0652342 ],\n",
       "       [-0.02635674],\n",
       "       [ 0.13626764],\n",
       "       [ 0.09742588]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16164133],\n",
       "       [-0.63541908],\n",
       "       [-0.67322023]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
